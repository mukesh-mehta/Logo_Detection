{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logo classification on Flickr27 Logo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mukesh/miniconda3/envs/statoil/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = \"flickr_logos_27_dataset/flickr_logos_27_dataset_training_set_annotation.txt\"\n",
    "test_file = \"flickr_logos_27_dataset/flickr_logos_27_dataset_query_set_annotation.txt\"\n",
    "image_dir = \"flickr_logos_27_dataset/flickr_logos_27_dataset_images/\"\n",
    "extra_img = \"more_images/\"\n",
    "new_size=(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_train = np.loadtxt(txt_file, dtype='a')\n",
    "annot_test = np.loadtxt(test_file, dtype='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing Images\n",
    "\n",
    "## Major Challenges\n",
    "Training data has 27 classes but test data set has 28 classes. Test data has an extra class \"none\". So, I added some new images to training data which do not have logos from SUN 397 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_train(annot,new_size=new_size):\n",
    "    fn = annot[0].decode('utf-8')\n",
    "    class_name = annot[1].decode('utf-8')\n",
    "    subset_class = annot[2].decode('utf-8')\n",
    "    x1 = int(annot[3].decode('utf-8'))\n",
    "    y1 = int(annot[4].decode('utf-8'))\n",
    "    x2 = int(annot[5].decode('utf-8'))\n",
    "    y2 = int(annot[6].decode('utf-8'))\n",
    "    img = Image.open(image_dir+fn)\n",
    "    area = (x1, y1, x2, y2)\n",
    "    img= img.crop(area)\n",
    "    img = img.resize((new_size))\n",
    "    return img, class_name\n",
    "\n",
    "def parse_test(annot,new_size=new_size):\n",
    "    fn = annot[0].decode('utf-8')\n",
    "    class_name = annot[1].decode('utf-8')\n",
    "    img = Image.open(image_dir+fn)\n",
    "    img = img.resize((new_size))\n",
    "    return img, class_name\n",
    "\n",
    "def new_img_to_train(images,new_size=new_size):\n",
    "    img = Image.open(images)\n",
    "    img = img.resize(new_size)\n",
    "    class_name ='none'\n",
    "    return img, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4616, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  labels\n",
       "0  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "1  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "2  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "3  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "4  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_=[]\n",
    "images=[]\n",
    "for annot in annot_train:\n",
    "    img,class_name = parse_train(annot)\n",
    "    images.append(img)\n",
    "    class_.append(class_name)\n",
    "    \n",
    "for fn in glob.glob(extra_img+'/*.jpg'):\n",
    "    img, class_name=new_img_to_train(fn)\n",
    "    images.append(img)\n",
    "    class_.append(class_name)\n",
    "data=pd.DataFrame(data={'image':images,'labels':class_})\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=128x128 a...</td>\n",
       "      <td>Adidas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  labels\n",
       "0  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "1  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "2  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "3  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas\n",
       "4  <PIL.Image.Image image mode=RGB size=128x128 a...  Adidas"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_=[]\n",
    "images=[]\n",
    "for annot in annot_test:\n",
    "    img,class_name = parse_test(annot)\n",
    "    images.append(img)\n",
    "    class_.append(class_name)\n",
    "test_data=pd.DataFrame(data={'image':images,'labels':class_})\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_OHE(label,nb_classes):\n",
    "    L_enc = LabelEncoder()\n",
    "    L_enc.fit(label)\n",
    "    return np_utils.to_categorical(L_enc.transform(label), nb_classes)\n",
    "\n",
    "def inverse_OHE(label,encoded_labels,nb_classes):\n",
    "    decoded=encoded_labels.argmax(1)\n",
    "    L_enc = LabelEncoder()\n",
    "    L_enc.fit(label)\n",
    "    return L_enc.inverse_transform(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels=to_OHE(data['labels'],len(set(data['labels'])))\n",
    "test_labels=to_OHE(test_data['labels'],len(set(test_data['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_images = np.array([np.array(im) for im in data['image']])\n",
    "test_images = np.array([np.array(im) for im in test_data['image']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Dropout, Activation, Conv2D, MaxPooling2D, Lambda, Flatten, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop, nadam, adam\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_trained_vgg():\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, \n",
    "                 input_shape=tr_images.shape[1:], classes=len(set(data['labels'])))\n",
    "    x = base_model.get_layer('conv_pw_13_relu').output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    FC = Dense(128, activation='relu')(x)\n",
    "    FC = Dropout(0.4)(FC)\n",
    "    preds = Dense(len(set(data['labels'])), activation='sigmoid')(FC)\n",
    "    model = Model(inputs=base_model.input,outputs=preds)\n",
    "    model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer=adam(lr=0.001))\n",
    "    return model\n",
    "\n",
    "def limit_mem():\n",
    "    import keras.backend as K\n",
    "    K.get_session().close()\n",
    "    cfg = K.tf.ConfigProto()\n",
    "    cfg.gpu_options.allow_growth = True\n",
    "    K.set_session(K.tf.Session(config=cfg))\n",
    "    print('gpu memory cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu memory cleaned\n",
      "Train on 4154 samples, validate on 462 samples\n",
      "Epoch 1/10\n",
      "4154/4154 [==============================] - 32s 8ms/step - loss: 0.0985 - acc: 0.9597 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 2/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0045 - val_acc: 0.9987\n",
      "Epoch 3/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0193 - val_acc: 0.9960\n",
      "Epoch 4/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 5/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0100 - val_acc: 0.9978\n",
      "Epoch 6/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0018 - val_acc: 0.9996\n",
      "Epoch 7/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9988\n",
      "Epoch 8/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0021 - val_acc: 0.9992\n",
      "Epoch 9/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0056 - val_acc: 0.9983\n",
      "Epoch 10/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0122 - val_acc: 0.9974\n",
      "462/462 [==============================] - 1s 2ms/step\n",
      "validation results 0.012173020402694362 0.9973716805507611\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.1693673197593954 0.9756613815272296\n",
      "270/270 [==============================] - 1s 3ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4154 samples, validate on 462 samples\n",
      "Epoch 1/10\n",
      "4154/4154 [==============================] - 33s 8ms/step - loss: 0.0985 - acc: 0.9606 - val_loss: 0.0122 - val_acc: 0.9967\n",
      "Epoch 2/10\n",
      "4154/4154 [==============================] - 29s 7ms/step - loss: 0.0114 - acc: 0.9967 - val_loss: 0.0019 - val_acc: 0.9995\n",
      "Epoch 3/10\n",
      "4154/4154 [==============================] - 29s 7ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0013 - val_acc: 0.9996\n",
      "Epoch 4/10\n",
      "4154/4154 [==============================] - 27s 7ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0037 - val_acc: 0.9985\n",
      "Epoch 5/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 6/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0017 - val_acc: 0.9992\n",
      "Epoch 7/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 4.5098e-04 - val_acc: 0.9999\n",
      "Epoch 8/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0137 - val_acc: 0.9957\n",
      "Epoch 9/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0018 - val_acc: 0.9995\n",
      "Epoch 10/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0018 - val_acc: 0.9994\n",
      "462/462 [==============================] - 1s 2ms/step\n",
      "validation results 0.001839872426289317 0.9993815726532048\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.14224205166101456 0.975264557202657\n",
      "270/270 [==============================] - 1s 4ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4154 samples, validate on 462 samples\n",
      "Epoch 1/10\n",
      "4154/4154 [==============================] - 27s 7ms/step - loss: 0.1064 - acc: 0.9561 - val_loss: 0.0048 - val_acc: 0.9988\n",
      "Epoch 2/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0028 - val_acc: 0.9991\n",
      "Epoch 3/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0050 - val_acc: 0.9985\n",
      "Epoch 4/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 5/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0022 - val_acc: 0.9991\n",
      "Epoch 6/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0465 - val_acc: 0.9902\n",
      "Epoch 7/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 8/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0014 - val_acc: 0.9996\n",
      "Epoch 9/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0035 - val_acc: 0.9991\n",
      "Epoch 10/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 0.9988\n",
      "462/462 [==============================] - 1s 2ms/step\n",
      "validation results 0.003922778758339776 0.9987631458224673\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.17442335889295296 0.9755291060165122\n",
      "270/270 [==============================] - 1s 5ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4154 samples, validate on 462 samples\n",
      "Epoch 1/10\n",
      "4154/4154 [==============================] - 28s 7ms/step - loss: 0.1060 - acc: 0.9576 - val_loss: 0.0064 - val_acc: 0.9980\n",
      "Epoch 2/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0125 - acc: 0.9962 - val_loss: 0.0032 - val_acc: 0.9991\n",
      "Epoch 3/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Epoch 4/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0017 - val_acc: 0.9996\n",
      "Epoch 5/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0155 - val_acc: 0.9964\n",
      "Epoch 6/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Epoch 7/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0059 - val_acc: 0.9987\n",
      "Epoch 8/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0020 - val_acc: 0.9997\n",
      "Epoch 9/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0051 - val_acc: 0.9992\n",
      "Epoch 10/10\n",
      "4154/4154 [==============================] - 25s 6ms/step - loss: 0.0083 - acc: 0.9973 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "462/462 [==============================] - 1s 2ms/step\n",
      "validation results 0.006096714626338538 0.998144717443557\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.18349960965138895 0.9735449795369748\n",
      "270/270 [==============================] - 2s 6ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4154 samples, validate on 462 samples\n",
      "Epoch 1/10\n",
      "4154/4154 [==============================] - 29s 7ms/step - loss: 0.1093 - acc: 0.9556 - val_loss: 0.0080 - val_acc: 0.9973\n",
      "Epoch 2/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0118 - acc: 0.9965 - val_loss: 0.0080 - val_acc: 0.9979\n",
      "Epoch 3/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 4/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0042 - val_acc: 0.9985\n",
      "Epoch 5/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0051 - val_acc: 0.9990\n",
      "Epoch 6/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0055 - val_acc: 0.9986\n",
      "Epoch 7/10\n",
      "4154/4154 [==============================] - 23s 6ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0062 - val_acc: 0.9985\n",
      "Epoch 8/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0084 - val_acc: 0.9974\n",
      "Epoch 9/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 10/10\n",
      "4154/4154 [==============================] - 23s 6ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0053 - val_acc: 0.9989\n",
      "462/462 [==============================] - 1s 2ms/step\n",
      "validation results 0.005279806485917744 0.9989177525301516\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.17586919082915065 0.977645508006767\n",
      "270/270 [==============================] - 2s 6ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4154 samples, validate on 462 samples\n",
      "Epoch 1/10\n",
      "4154/4154 [==============================] - 30s 7ms/step - loss: 0.1243 - acc: 0.9487 - val_loss: 0.0078 - val_acc: 0.9970\n",
      "Epoch 2/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0139 - acc: 0.9959 - val_loss: 0.0023 - val_acc: 0.9992\n",
      "Epoch 3/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0020 - val_acc: 0.9995\n",
      "Epoch 4/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 6.0413e-04 - val_acc: 0.9997\n",
      "Epoch 5/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0176 - val_acc: 0.9947\n",
      "Epoch 6/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0031 - val_acc: 0.9987\n",
      "Epoch 7/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.0029 - val_acc: 0.9991\n",
      "Epoch 8/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0028 - val_acc: 0.9994\n",
      "Epoch 9/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "Epoch 10/10\n",
      "4154/4154 [==============================] - 24s 6ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0054 - val_acc: 0.9986\n",
      "462/462 [==============================] - 1s 2ms/step\n",
      "validation results 0.005421665507504886 0.9986085404049266\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.20356165046493213 0.9757936694003918\n",
      "270/270 [==============================] - 2s 7ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4155 samples, validate on 461 samples\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 30s 7ms/step - loss: 0.1164 - acc: 0.9521 - val_loss: 0.0082 - val_acc: 0.9977\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0041 - val_acc: 0.9991\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0033 - val_acc: 0.9994\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0039 - val_acc: 0.9988\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0034 - val_acc: 0.9990\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0101 - val_acc: 0.9976\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0044 - val_acc: 0.9987\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0111 - val_acc: 0.9970\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0083 - val_acc: 0.9976\n",
      "461/461 [==============================] - 1s 2ms/step\n",
      "validation results 0.008299078090333903 0.9975983936202242\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.1911281994509476 0.9764550372406289\n",
      "270/270 [==============================] - 2s 7ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4155 samples, validate on 461 samples\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 32s 8ms/step - loss: 0.1215 - acc: 0.9495 - val_loss: 0.0103 - val_acc: 0.9964\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0095 - val_acc: 0.9971\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0039 - val_acc: 0.9988\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0052 - val_acc: 0.9985\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0173 - val_acc: 0.9954\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0186 - val_acc: 0.9964\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0074 - val_acc: 0.9977\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0045 - val_acc: 0.9991\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "461/461 [==============================] - 1s 2ms/step\n",
      "validation results 0.00533393962446108 0.9980632177919732\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.16821539785574985 0.9779100643263923\n",
      "270/270 [==============================] - 2s 8ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4155 samples, validate on 461 samples\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 30s 7ms/step - loss: 0.0971 - acc: 0.9622 - val_loss: 0.0109 - val_acc: 0.9967\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0035 - val_acc: 0.9991\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0081 - val_acc: 0.9977\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0090 - val_acc: 0.9975\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0096 - val_acc: 0.9975\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0092 - val_acc: 0.9976\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0035 - val_acc: 0.9993\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0031 - val_acc: 0.9991\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0062 - val_acc: 0.9981\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0067 - val_acc: 0.9986\n",
      "461/461 [==============================] - 1s 2ms/step\n",
      "validation results 0.006655311884797079 0.998605519339216\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.18120153648433862 0.9730158739619785\n",
      "270/270 [==============================] - 3s 10ms/step\n",
      "gpu memory cleaned\n",
      "Train on 4155 samples, validate on 461 samples\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 31s 8ms/step - loss: 0.1020 - acc: 0.9585 - val_loss: 0.0091 - val_acc: 0.9969\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.0042 - val_acc: 0.9986\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0069 - val_acc: 0.9979\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 24s 6ms/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.0038 - val_acc: 0.9985\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0125 - val_acc: 0.9960\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0250 - val_acc: 0.9937\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0026 - val_acc: 0.9991\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0134 - val_acc: 0.9972\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0036 - val_acc: 0.9988\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 23s 6ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0012 - val_acc: 0.9996\n",
      "461/461 [==============================] - 1s 2ms/step\n",
      "validation results 0.0012010575265360148 0.9996126449289136\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "test results 0.17293200326686795 0.9776455022670605\n",
      "270/270 [==============================] - 3s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "folds=KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "predict=np.zeros((len(test_images), 28))\n",
    "for train,test in folds.split(tr_images,data_labels):\n",
    "    limit_mem()\n",
    "    X_train, X_test = tr_images[train], tr_images[test]\n",
    "    Y_train, Y_test = data_labels[train], data_labels[test]\n",
    "    model=None\n",
    "    model=pre_trained_vgg()\n",
    "    hist=model.fit(X_train/255,Y_train, validation_data=(X_test/255, Y_test),epochs=10, batch_size=16,verbose=1)\n",
    "    preds=model.evaluate(X_test/255,Y_test,batch_size=16, verbose=1)\n",
    "    print(\"validation results\" ,preds[0], preds[1])\n",
    "    test_pred = model.evaluate(test_images/255,test_labels,batch_size=16, verbose=1)\n",
    "    print(\"test results\", test_pred[0], test_pred[1])\n",
    "    predict +=model.predict(test_images,batch_size=16, verbose=1)\n",
    "    del test_pred,preds,hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statoil",
   "language": "python",
   "name": "statoil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
